{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LpojGuWuL7b-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nussl\n",
    "import torch\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "#from models.Waveform import Waveform\n",
    "#from models.MaskInference import MaskInference\n",
    "from models.WaveUNet import WaveUNet\n",
    "from utils import utils, data\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data.prepare_musdbhq(folder='data/musdb18hq/',musdb_root='/SFS/user/ry/stonekev/.nussl/',download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.logger()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MAX_MIXTURES = int(1e8) # We'll set this to some impossibly high number for on the fly mixing.\n",
    "\n",
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128)\n",
    "\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "    nussl_tfm.GetAudio(),\n",
    "    #nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_audio', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])\n",
    "\n",
    "train_folder = \"~/audio_isolation/data/musdb18hq/train\"\n",
    "val_folder = \"~/audio_isolation/data/musdb18hq/test\"\n",
    "\n",
    "train_data = data.on_the_fly(stft_params, transform=tfm, \n",
    "    fg_path=train_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, num_workers=1, batch_size=10)\n",
    "\n",
    "val_data = data.on_the_fly(stft_params, transform=tfm, \n",
    "    fg_path=val_folder, num_mixtures=10, coherent_prob=1.0)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_data, num_workers=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 220500])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_data[0]['mix_audio'].double()\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 220500])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimates': tensor([[[[ 0.0906],\n",
      "          [-0.1465],\n",
      "          [ 0.2081],\n",
      "          ...,\n",
      "          [-0.2285],\n",
      "          [-0.2699],\n",
      "          [-0.3821]]]], dtype=torch.float64, grad_fn=<UnsqueezeBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "sample = train_data[0]['mix_audio'].unsqueeze(0).double()\n",
    "sample_model = WaveUNet().double()\n",
    "sample_out = sample_model.forward(sample.double())\n",
    "print(sample_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WaveUNet(\n",
       "  (down_conv1): Sequential(\n",
       "    (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_conv2): Sequential(\n",
       "    (0): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_conv3): Sequential(\n",
       "    (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_conv4): Sequential(\n",
       "    (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (down_conv5): Sequential(\n",
       "    (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (transpose1): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,))\n",
       "  (up_conv1): Sequential(\n",
       "    (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (transpose2): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,), output_padding=(1,))\n",
       "  (up_conv2): Sequential(\n",
       "    (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (transpose3): ConvTranspose1d(64, 32, kernel_size=(2,), stride=(2,))\n",
       "  (up_conv3): Sequential(\n",
       "    (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (transpose4): ConvTranspose1d(32, 16, kernel_size=(2,), stride=(2,))\n",
       "  (up_conv4): Sequential(\n",
       "    (0): Conv1d(32, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "    (4): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (out): Conv1d(16, 1, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WaveUNet.build()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nussl.ml.train.loss.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'WaveUNet',\n",
       " 'modules': {'model': {'class': 'WaveUNet',\n",
       "   'args': {'in_channels': 1, 'out_channels': 1, 'features': 32},\n",
       "   'module_snapshot': \"class WaveUNet(nn.Module):\\n    def __init__(self, in_channels=1, out_channels=1, features=16):\\n        super(WaveUNet, self).__init__()\\n        self.in_channels = in_channels\\n        self.out_channels = out_channels\\n        self.features = features\\n    \\n        self.down_conv1 = WaveUNet.conv_block(self.in_channels, self.features)\\n        self.down_conv2 = WaveUNet.conv_block(self.features, self.features*2)\\n        self.down_conv3 = WaveUNet.conv_block(self.features*2, self.features*4)\\n        self.down_conv4 = WaveUNet.conv_block(self.features*4, self.features*8)\\n        self.down_conv5 = WaveUNet.conv_block(self.features*8, self.features*16)\\n        \\n        self.max_pool = nn.MaxPool1d(kernel_size=2, stride=2)\\n        \\n        self.transpose1 = nn.ConvTranspose1d(self.features*16, self.features*8, kernel_size=2, stride=2)\\n        self.up_conv1 = WaveUNet.conv_block(self.features*16, self.features*8)\\n        self.transpose2 = nn.ConvTranspose1d(self.features*8, self.features*4, kernel_size=2, stride=2, output_padding=1)\\n        self.up_conv2 = WaveUNet.conv_block(self.features*8, self.features*4)\\n        self.transpose3 = nn.ConvTranspose1d(self.features*4, self.features*2, kernel_size=2, stride=2)\\n        self.up_conv3 = WaveUNet.conv_block(self.features*4, self.features*2)\\n        self.transpose4 = nn.ConvTranspose1d(self.features*2, self.features, kernel_size=2, stride=2)\\n        self.up_conv4 = WaveUNet.conv_block(self.features*2, self.features)\\n        \\n        self.out = nn.Conv1d(self.features, self.out_channels, kernel_size=1)\\n\\n    def forward(self, data):\\n        \\n        # mix_magnitude = data.unsqueeze(4) # save for masking\\n        # data = data.transpose(3, 1).transpose(2, 3)\\n        \\n        down_conv1 = self.down_conv1(data)\\n        down_conv1_max = self.max_pool(down_conv1)\\n        down_conv2 = self.down_conv2(down_conv1_max)\\n        down_conv2_max = self.max_pool(down_conv2)\\n        down_conv3 = self.down_conv3(down_conv2_max)\\n        down_conv3_max = self.max_pool(down_conv3)\\n        down_conv4 = self.down_conv4(down_conv3_max)\\n        down_conv4_max = self.max_pool(down_conv4)\\n        \\n        down_conv5 = self.down_conv5(down_conv4_max)\\n\\n        trans1 = self.transpose1(down_conv5)\\n        up_conv1 = self.up_conv1(torch.cat([down_conv4, trans1], 1))\\n        trans2 = self.transpose2(up_conv1)\\n        up_conv2 = self.up_conv2(torch.cat([down_conv3, trans2], 1))\\n        trans3 = self.transpose3(up_conv2)\\n        up_conv3 = self.up_conv3(torch.cat([down_conv2, trans3], 1))\\n        trans4 = self.transpose4(up_conv3)\\n        up_conv4 = self.up_conv4(torch.cat([down_conv1, trans4], 1))\\n        \\n        estimates = self.out(up_conv4).unsqueeze(3)\\n        #mask = mask.transpose(1, 3).transpose(1, 2).unsqueeze(4)\\n        \\n        # estimates = mix_magnitude * mask\\n        \\n        output = {\\n            'estimates': estimates\\n        }\\n        \\n        return output\\n\\n    @staticmethod\\n    def conv_block(in_channels, features):\\n        \\n        conv = nn.Sequential(\\n            nn.Conv1d(in_channels, features, kernel_size=3, padding=1),\\n            nn.BatchNorm1d(features),\\n            nn.ReLU(inplace=True),\\n            nn.Conv1d(features, features, kernel_size=3, padding=1),\\n            nn.BatchNorm1d(features),\\n            nn.ReLU(inplace=True)\\n        )\\n        \\n        return conv\\n    \\n    # Added function\\n    @classmethod\\n    def build(cls, in_channels=1, out_channels=1, features=16):\\n        # Step 1. Register our model with nussl\\n        nussl.ml.register_module(cls)\\n        \\n        # Step 2a: Define the building blocks.\\n        modules = {\\n            'model': {\\n                'class': 'WaveUNet',\\n                'args': {\\n                    # 'num_features': num_features,\\n                    # 'num_audio_channels': num_audio_channels,\\n                    # 'hidden_size': hidden_size,\\n                    # 'num_layers': num_layers,\\n                    # 'bidirectional': bidirectional,\\n                    # 'dropout': dropout,\\n                    # 'num_sources': num_sources,\\n                    # 'activation': activation\\n                    'in_channels': in_channels,\\n                    'out_channels': out_channels,\\n                    'features': features\\n                }\\n            }\\n        }\\n        \\n        \\n        # Step 2b: Define the connections between input and output.\\n        # Here, the mix_magnitude key is the only input to the model.\\n        connections = [\\n            ['model', ['mix_audio']]\\n        ]\\n        \\n        # Step 2c. The model outputs a dictionary, which SeparationModel will\\n        # change the keys to model:mask, model:estimates. The lines below \\n        # alias model:mask to just mask, and model:estimates to estimates.\\n        # This will be important later when we actually deploy our model.\\n        for key in ['estimates']:\\n            modules[key] = {'class': 'Alias'}\\n            connections.append([key, [f'model:{key}']])\\n        \\n        # Step 2d. There are two outputs from our SeparationModel: estimates and mask.\\n        # Then put it all together.\\n        output = ['estimates']\\n        config = {\\n            'name': cls.__name__,\\n            'modules': modules,\\n            'connections': connections,\\n            'output': output\\n        }\\n        # Step 3. Instantiate the model as a SeparationModel.\\n        return nussl.ml.SeparationModel(config)\\n\"},\n",
       "  'estimates': {'class': 'Alias',\n",
       "   'module_snapshot': 'class Alias(nn.Module):\\n    \"\"\"\\n    Super simple module that just passes the data through without altering it, so\\n    that the output of a model can be renamed in a SeparationModel.\\n    \"\"\"\\n    def forward(self, data):\\n        return data\\n',\n",
       "   'args': {}}},\n",
       " 'connections': [['model', ['mix_audio']], ['estimates', ['model:estimates']]],\n",
       " 'output': ['estimates']}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeparationModel(\n",
       "  (layers): ModuleDict(\n",
       "    (model): WaveUNet(\n",
       "      (down_conv1): Sequential(\n",
       "        (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (down_conv2): Sequential(\n",
       "        (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (down_conv3): Sequential(\n",
       "        (0): Conv1d(64, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (down_conv4): Sequential(\n",
       "        (0): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (down_conv5): Sequential(\n",
       "        (0): Conv1d(256, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (transpose1): ConvTranspose1d(512, 256, kernel_size=(2,), stride=(2,))\n",
       "      (up_conv1): Sequential(\n",
       "        (0): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (transpose2): ConvTranspose1d(256, 128, kernel_size=(2,), stride=(2,), output_padding=(1,))\n",
       "      (up_conv2): Sequential(\n",
       "        (0): Conv1d(256, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (transpose3): ConvTranspose1d(128, 64, kernel_size=(2,), stride=(2,))\n",
       "      (up_conv3): Sequential(\n",
       "        (0): Conv1d(128, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (transpose4): ConvTranspose1d(64, 32, kernel_size=(2,), stride=(2,))\n",
       "      (up_conv4): Sequential(\n",
       "        (0): Conv1d(64, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "      (out): Conv1d(32, 1, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (estimates): Alias()\n",
       "  )\n",
       ")\n",
       "Number of parameters: 2710753"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "executionInfo": {
     "elapsed": 9695,
     "status": "error",
     "timestamp": 1681264532589,
     "user": {
      "displayName": "Devin Cortese",
      "userId": "18217987079678842733"
     },
     "user_tz": 240
    },
    "id": "BMvsvbyJGxVB",
    "outputId": "367c59f2-1e56-445a-ad46-7afd3c966b12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2023 07:13:51 PM | engine.py:874 Engine run starting with max_epochs=2.\n",
      "04/27/2023 07:16:46 PM | engine.py:874 Engine run starting with max_epochs=1.\n",
      "04/27/2023 07:16:54 PM | engine.py:972 Epoch[1] Complete. Time taken: 00:00:07.925\n",
      "04/27/2023 07:16:54 PM | engine.py:988 Engine run complete. Time taken: 00:00:07.952\n",
      "04/27/2023 07:16:59 PM | trainer.py:311 \n",
      "\n",
      "EPOCH SUMMARY \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "- Epoch number: 0001 / 0002 \n",
      "- Training loss:   0.095486 \n",
      "- Validation loss: 0.059720 \n",
      "- Epoch took: 0:03:08.109681 \n",
      "- Time since start: 0:03:08.109726 \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "Saving to /Users/dev/audio_isolation/checkpoints/best.model.pth. \n",
      "Output @ /Users/dev/audio_isolation \n",
      "\n",
      "04/27/2023 07:16:59 PM | engine.py:972 Epoch[1] Complete. Time taken: 00:03:00.665\n",
      "04/27/2023 07:17:20 PM | engine.py:992 Engine run is terminating due to exception: \n"
     ]
    }
   ],
   "source": [
    "# nf = stft_params.window_length // 2 + 1\n",
    "# model = Waveform.build(nf, 1, 50, 1, True, 0.0, 1, 'sigmoid')\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# loss_fn = nussl.ml.train.loss.L1Loss()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_audio'],\n",
    "    )\n",
    "    \n",
    "    loss.backward() # backwards + gradient step\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    \n",
    "    return loss_vals\n",
    "\n",
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_audio']\n",
    "    )    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(), \n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    return loss_vals\n",
    "\n",
    "# Create the engines\n",
    "trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n",
    "    train_step, val_step, device=DEVICE\n",
    ")\n",
    "\n",
    "# We'll save the output relative to this notebook.\n",
    "output_folder = Path('.').absolute()\n",
    "\n",
    "# Adding handlers from nussl that print out details about model training\n",
    "# run the validation step, and save the models.\n",
    "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
    "nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n",
    "    optimizer, train_data, trainer, val_dataloader, validator)\n",
    "\n",
    "trainer.run(\n",
    "    train_dataloader, \n",
    "    epoch_length=10, \n",
    "    max_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ugIDanf4GxVF",
    "outputId": "2c025fca-07e0-4e80-ec75-c7ba500ea311"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/base/separation_base.py:73: UserWarning: input_audio_signal has no data!\n",
      "  warnings.warn('input_audio_signal has no data!')\n",
      "/Users/dev/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/core/audio_signal.py:455: UserWarning: Initializing STFT with data that is non-complex. This might lead to weird results!\n",
      "  warnings.warn('Initializing STFT with data that is non-complex. '\n"
     ]
    }
   ],
   "source": [
    "separator = nussl.separation.deep.DeepMaskEstimation(\n",
    "    nussl.AudioSignal(), model_path='checkpoints/best.model.pth',\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m item \u001b[39m=\u001b[39m test_data[\u001b[39m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m separator\u001b[39m.\u001b[39maudio_signal \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39mmix\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m estimates \u001b[39m=\u001b[39m separator()\n\u001b[1;32m     10\u001b[0m \u001b[39m# Since our model only returns one source, let's tack on the\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# residual (which should be accompaniment)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m estimates\u001b[39m.\u001b[39mappend(item[\u001b[39m'\u001b[39m\u001b[39mmix\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m estimates[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/base/separation_base.py:194\u001b[0m, in \u001b[0;36mSeparationBase.__call__\u001b[0;34m(self, audio_signal, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m audio_signal \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_signal \u001b[39m=\u001b[39m audio_signal\n\u001b[0;32m--> 194\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    195\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_audio_signals()\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/deep/deep_mask_estimation.py:53\u001b[0m, in \u001b[0;36mDeepMaskEstimation.run\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult_masks \u001b[39m=\u001b[39m []\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m masks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward()\n\u001b[1;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(masks\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]):\n\u001b[1;32m     56\u001b[0m     mask_data \u001b[39m=\u001b[39m masks[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, i]\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/deep/deep_mask_estimation.py:35\u001b[0m, in \u001b[0;36mDeepMaskEstimation.forward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m input_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_input_data_for_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 35\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_data)\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m output:\n\u001b[1;32m     37\u001b[0m         \u001b[39mraise\u001b[39;00m SeparationException(\n\u001b[1;32m     38\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis model is not a deep mask estimation model! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mDid not find \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m\u001b[39m key in output dictionary.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/ml/networks/separation_model.py:181\u001b[0m, in \u001b[0;36mSeparationModel.forward\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m             input_data\u001b[39m.\u001b[39mappend(output[c] \u001b[39mif\u001b[39;00m c \u001b[39min\u001b[39;00m output \u001b[39melse\u001b[39;00m data[c])\n\u001b[0;32m--> 181\u001b[0m _output \u001b[39m=\u001b[39m layer(\u001b[39m*\u001b[39;49minput_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    182\u001b[0m added_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(_output, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/audio_isolation/models/WaveUNet.py:42\u001b[0m, in \u001b[0;36mWaveUNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     40\u001b[0m down_conv1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_conv1(data)\n\u001b[1;32m     41\u001b[0m down_conv1_max \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_pool(down_conv1)\n\u001b[0;32m---> 42\u001b[0m down_conv2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_conv2(down_conv1_max)\n\u001b[1;32m     43\u001b[0m down_conv2_max \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_pool(down_conv2)\n\u001b[1;32m     44\u001b[0m down_conv3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_conv3(down_conv2_max)\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "from utils import viz\n",
    "\n",
    "test_folder = \"~/audio_isolation/data/tutorial/test/\"\n",
    "test_data = data.mixer(stft_params, transform=None, \n",
    "    fg_path=test_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n",
    "item = test_data[0]\n",
    "\n",
    "separator.audio_signal = item['mix']\n",
    "estimates = separator()\n",
    "# Since our model only returns one source, let's tack on the\n",
    "# residual (which should be accompaniment)\n",
    "estimates.append(item['mix'] - estimates[0])\n",
    "\n",
    "viz.show_sources(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-Xwu3xBGxVG"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "])\n",
    "#test_dataset = nussl.datasets.MUSDB18(subsets=['test'], transform=tfm)\n",
    "test_dataset = data.mixer(stft_params, transform=tfm, \n",
    "    fg_path=test_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n",
    "\n",
    "# Just do 5 items for speed. Change to 50 for actual experiment.\n",
    "for i in range(5):\n",
    "    item = test_dataset[i]\n",
    "    separator.audio_signal = item['mix']\n",
    "    estimates = separator()\n",
    "\n",
    "    source_keys = list(item['sources'].keys())\n",
    "    estimates = {\n",
    "        'vocals': estimates[0],\n",
    "        'bass+drums+other': item['mix'] - estimates[0]\n",
    "    }\n",
    "\n",
    "    sources = [item['sources'][k] for k in source_keys]\n",
    "    estimates = [estimates[k] for k in source_keys]\n",
    "\n",
    "    evaluator = nussl.evaluation.BSSEvalScale(\n",
    "        sources, estimates, source_labels=source_keys\n",
    "    )\n",
    "    scores = evaluator.evaluate()\n",
    "    output_folder = Path(output_folder).absolute()\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "    output_file = output_folder / sources[0].file_name.replace('wav', 'json') # Path(str(separator.audio_signal.file_name) + '.json')\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2X4GapzGxVH",
    "outputId": "98325d02-0c42-4fe9-d71f-e087dd3934d9"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "json_files = glob.glob(f\"*.json\")\n",
    "df = nussl.evaluation.aggregate_score_files(\n",
    "    json_files, aggregator=np.nanmedian)\n",
    "nussl.evaluation.associate_metrics(separator.model, df, test_dataset)\n",
    "report_card = nussl.evaluation.report_card(\n",
    "    df, report_each_source=True)\n",
    "print(report_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqD3uFSkGxVH",
    "outputId": "087131df-0e37-4458-dacd-10e4bd8af75a"
   },
   "outputs": [],
   "source": [
    "separator.model.save('checkpoints/best.model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPuwc-RqGxVH"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = torch.load('checkpoints/best.model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6mM1Z0LGxVI",
    "outputId": "665fb444-a6fe-4307-8266-a1250a1b4d15"
   },
   "outputs": [],
   "source": [
    "model_checkpoint['metadata'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC6oQBFmGxVI",
    "outputId": "fdb01bd4-54ea-4ea1-a75a-d26bd9fe9691"
   },
   "outputs": [],
   "source": [
    "model_checkpoint['metadata']['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcQg01dbGxVI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
