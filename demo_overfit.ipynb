{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5808f6df-a402-4e2b-ae66-0b6a84b3081d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nussl\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "from nussl.ml.networks.modules import BatchNorm, RecurrentStack, Embedding, STFT, LearnedFilterBank, AmplitudeToDB\n",
    "from models.MaskInference import MaskInference\n",
    "from models.UNet import UNetSpect\n",
    "from models.Filterbank import Filterbank\n",
    "from utils import utils, data, viz\n",
    "from pathlib import Path\n",
    "import yaml, argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0cdb21e-efcc-4f97-8ccb-0ef2a671bfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load yaml configs into configs dictionary\n",
    "with open('config/filterbank.yml','r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ceed07-f65b-4ec4-b318-cbef3c1fb8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.logger()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_type = configs['model_type']\n",
    "model_dict = {'Mask': MaskInference,\n",
    "              'UNet': UNetSpect,\n",
    "              'Filterbank':Filterbank\n",
    "             }\n",
    "waveform_models = ['Filterbank']\n",
    "assert model_type in model_dict.keys(), f'Model type must be one of {model_dict.keys()}'\n",
    "\n",
    "if model_type in waveform_models:\n",
    "    stft_params = None\n",
    "    \n",
    "    tfm = nussl_tfm.Compose([\n",
    "        nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "        nussl_tfm.GetAudio(),\n",
    "        nussl_tfm.IndexSources('source_audio', 1),\n",
    "        nussl_tfm.ToSeparationModel(),\n",
    "    ])\n",
    "    \n",
    "    target_key = 'source_audio'\n",
    "    output_key = 'audio'\n",
    "    \n",
    "else:\n",
    "    stft_params = nussl.STFTParams(**configs['stft_params'])\n",
    "    \n",
    "    tfm = nussl_tfm.Compose([\n",
    "        nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "        nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "        nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "        nussl_tfm.ToSeparationModel(),\n",
    "    ])\n",
    "    \n",
    "    target_key = 'source_magnitudes'\n",
    "    output_key = 'estimates'\n",
    "\n",
    "\n",
    "configs['batch_size'] = 1\n",
    "configs['train_generator_params']['num_mixtures']=10\n",
    "configs['valid_generator_params']['num_mixtures']=1\n",
    "\n",
    "duration=5\n",
    "\n",
    "train_data = data.on_the_fly(stft_params, transform=tfm, fg_path=configs['test_folder'], **configs['train_generator_params'], duration=duration)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, num_workers=1, batch_size=configs['batch_size'])\n",
    "\n",
    "val_data = data.on_the_fly(stft_params, transform=tfm, fg_path=configs['test_folder'], **configs['valid_generator_params'], duration=duration)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, num_workers=1, batch_size=configs['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e7048d-e510-4d8f-aa67-91e3a0ba4123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overfit_selection=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5d1f42-6f9f-4c6b-aecd-244c18251657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_type = configs['loss_type']\n",
    "loss_dict = {'L1': nussl.ml.train.loss.L1Loss,\n",
    "             'L2': nussl.ml.train.loss.MSELoss,\n",
    "             'MSE': nussl.ml.train.loss.MSELoss,}\n",
    "assert loss_type in loss_dict.keys(), f'Loss type must be one of {loss_dict.keys()}'\n",
    "loss_fn = loss_dict[loss_type]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e350b9-02c7-4455-be2c-9648a073b433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Forward pass\n",
    "    output = model(batch)\n",
    "    loss = loss_fn(output[output_key],batch[target_key])\n",
    "    \n",
    "    #Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vals = {'loss':loss.item()}\n",
    "    \n",
    "    return loss_vals\n",
    "\n",
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(batch)\n",
    "    loss = loss_fn(output[output_key],batch[target_key])  \n",
    "    loss_vals = {'loss':loss.item()}\n",
    "    return loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af54504b-28f3-44b1-9cbd-edde96fba28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set up the model and optimizer\n",
    "if model_type=='Mask':\n",
    "    model = MaskInference.build(stft_params.window_length//2+1, **configs['model_params']).to(device)\n",
    "elif model_type=='UNet':\n",
    "    model = UNetSpect.build(**configs['model_params']).to(device)\n",
    "elif model_type=='Filterbank':\n",
    "    model = Filterbank.build(**configs['model_params']).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), **configs['optimizer_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c9b3da7-6cd3-4f34-81de-bf5bcd47fa58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,batch in enumerate(train_dataloader):\n",
    "    if i==overfit_selection:\n",
    "        batch=batch\n",
    "        break\n",
    "    \n",
    "for key in batch:\n",
    "    if torch.is_tensor(batch[key]):\n",
    "        batch[key] = batch[key].float().to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efc994af-6680-4ddd-95df-8d35a168e97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs['optimizer_params']['lr'] = 1e-2\n",
    "optimizer = torch.optim.Adam(model.parameters(), **configs['optimizer_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd390164-607c-4656-9e4a-6cd028b98fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create nussl ML engine\n",
    "trainer, validator = nussl.ml.train.create_train_and_validation_engines(train_step, val_step, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1dcec74-4ecd-4415-bc19-7946cb1bba0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 18.027971 at iteration 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# For bookkeeping\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_ITERATIONS):\n\u001b[0;32m----> 5\u001b[0m     loss_val \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     loss_history\u001b[38;5;241m.\u001b[39mappend(loss_val[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m20\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output[output_key],batch[target_key])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#Backward pass\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     12\u001b[0m loss_vals \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m:loss\u001b[38;5;241m.\u001b[39mitem()}\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_ITERATIONS = 200\n",
    "loss_history = [] # For bookkeeping\n",
    "\n",
    "for i in range(N_ITERATIONS):\n",
    "    loss_val = train_step(trainer,batch)\n",
    "    loss_history.append(loss_val['loss'])\n",
    "    if i%20==0:\n",
    "        print(f'Loss: {loss_val[\"loss\"]:.6f} at iteration {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d91d025-8c9f-48f8-ac06-82daba08d853",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/SFS/user/ry/stonekev/miniconda3/envs/audio/lib/python3.10/site-packages/ignite/contrib/handlers/tqdm_logger.py:127: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "configs['train_params']['epoch_length']=2\n",
    "configs['optimizer_params']['lr'] = 1e-10\n",
    "optimizer = torch.optim.Adam(model.parameters(), **configs['optimizer_params'])\n",
    "\n",
    "\n",
    "\n",
    "# Save model outputs\n",
    "checkpoint_folder = Path('overfit').absolute()\n",
    "\n",
    "# Adding handlers from nussl that print out details about model training\n",
    "# run the validation step, and save the models.\n",
    "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
    "nussl.ml.train.add_validate_and_checkpoint(checkpoint_folder, model, optimizer, train_data, trainer, val_dataloader, validator)\n",
    "nussl.ml.train.add_progress_bar_handler(trainer, validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9bbbc8b-08fc-4ec1-a68f-76a54a0b1d9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs['train_params']['max_epochs']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6b26e68-9eab-4b2d-b52f-ea001907fc32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2023 09:18:41 PM | engine.py:876 Engine run resuming from iteration 1, epoch 1 until 1 epochs\n"
     ]
    }
   ],
   "source": [
    "trainer.run(train_dataloader, **configs['train_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca74829c-c8f3-45e6-b810-cc159f269d96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m target \u001b[38;5;241m=\u001b[39m batch[target_key]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m----> 2\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m estimates \u001b[38;5;241m=\u001b[39m output[output_key]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/nussl/ml/networks/separation_model.py:181\u001b[0m, in \u001b[0;36mSeparationModel.forward\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m             input_data\u001b[38;5;241m.\u001b[39mappend(output[c] \u001b[38;5;28;01mif\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m output \u001b[38;5;28;01melse\u001b[39;00m data[c])\n\u001b[0;32m--> 181\u001b[0m _output \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m added_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(_output, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/audio/audio_isolation/models/Filterbank.py:36\u001b[0m, in \u001b[0;36mFilterbank.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     34\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamplitude_to_db(mix_repr)\n\u001b[1;32m     35\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_normalization(data)\n\u001b[0;32m---> 36\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecurrent_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(data)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Mask the mixture spectrogram\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/nussl/ml/networks/modules/blocks.py:574\u001b[0m, in \u001b[0;36mRecurrentStack.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    572\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreshape(shape[\u001b[38;5;241m0\u001b[39m], shape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mflatten_parameters()\n\u001b[0;32m--> 574\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/audio/lib/python3.10/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "target = batch[target_key].detach().numpy()\n",
    "output = model(batch)\n",
    "estimates = output[output_key].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9effa9-c372-4b59-9c60-7541e54e4366",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55786b-5189-4acb-b54c-315e200890a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.max(target))\n",
    "print(np.max(estimates))\n",
    "print(np.min(target))\n",
    "print(np.min(estimates))\n",
    "print(np.std(target))\n",
    "print(np.std(estimates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786dcaf8-3861-49c1-b684-f1ad372da492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load in the model\n",
    "if model_type in waveform_models:\n",
    "    separator = nussl.separation.deep.DeepAudioEstimation(\n",
    "        nussl.AudioSignal(), model_path='overfit/checkpoints/latest.model.pth',\n",
    "        device='cpu',\n",
    "    )\n",
    "else:\n",
    "    separator = nussl.separation.deep.DeepMaskEstimation(\n",
    "        nussl.AudioSignal(), model_path='overfit/checkpoints/latest.model.pth',\n",
    "        device='cpu',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72275de-809c-46a8-9072-19e800e80eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test on the data\n",
    "test_folder = configs['test_folder']\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "])\n",
    "test_data = data.mixer(stft_params, transform=tfm, fg_path=configs['train_folder'], num_mixtures=1, coherent_prob=1.0, duration=5)\n",
    "\n",
    "test_data = data.on_the_fly(stft_params, transform=None, fg_path=configs['test_folder'], **configs['train_generator_params'], duration=duration)\n",
    "\n",
    "signal = test_data[overfit_selection]['mix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41413e-9a9e-4c43-8a88-d72ce3b8341c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "separator.audio_signal = signal\n",
    "estimates = separator()\n",
    "estimates.append(signal - estimates[0])\n",
    "viz.show_sources(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa25e3a-a7eb-420a-a8da-ba77280070b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
