{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5808f6df-a402-4e2b-ae66-0b6a84b3081d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import nussl\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "from nussl.ml.networks.modules import BatchNorm, RecurrentStack, Embedding, STFT, LearnedFilterBank, AmplitudeToDB\n",
    "from models.MaskInference import MaskInference\n",
    "from models.UNet import UNetSpect\n",
    "from models.Filterbank import Filterbank\n",
    "from utils import utils, data, viz\n",
    "from pathlib import Path\n",
    "import yaml, argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0cdb21e-efcc-4f97-8ccb-0ef2a671bfdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load yaml configs into configs dictionary\n",
    "with open('config/test_filterbank.yml','r') as f:\n",
    "    configs = yaml.safe_load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43ceed07-f65b-4ec4-b318-cbef3c1fb8a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utils.logger()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_type = configs['model_type']\n",
    "model_dict = {'Mask': MaskInference,\n",
    "              'UNet': UNetSpect,\n",
    "              'Filterbank':Filterbank\n",
    "             }\n",
    "waveform_models = ['Filterbank']\n",
    "assert model_type in model_dict.keys(), f'Model type must be one of {model_dict.keys()}'\n",
    "\n",
    "if model_type in waveform_models:\n",
    "    stft_params = None\n",
    "    \n",
    "    tfm = nussl_tfm.Compose([\n",
    "        nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "        nussl_tfm.GetAudio(),\n",
    "        nussl_tfm.IndexSources('source_audio', 1),\n",
    "        nussl_tfm.ToSeparationModel(),\n",
    "    ])\n",
    "    \n",
    "    target_key = 'source_audio'\n",
    "    output_key = 'audio'\n",
    "    \n",
    "else:\n",
    "    stft_params = nussl.STFTParams(**configs['stft_params'])\n",
    "    \n",
    "    tfm = nussl_tfm.Compose([\n",
    "        nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "        nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "        nussl_tfm.IndexSources('source_magnitudes', 1),\n",
    "        nussl_tfm.ToSeparationModel(),\n",
    "    ])\n",
    "    \n",
    "    target_key = 'source_magnitudes'\n",
    "    output_key = 'estimates'\n",
    "\n",
    "\n",
    "configs['batch_size'] = 1\n",
    "configs['train_generator_params']['num_mixtures']=10\n",
    "configs['valid_generator_params']['num_mixtures']=1\n",
    "\n",
    "duration=5\n",
    "\n",
    "train_data = data.on_the_fly(stft_params, transform=tfm, fg_path=configs['test_folder'], **configs['train_generator_params'], duration=duration)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_data, num_workers=1, batch_size=configs['batch_size'])\n",
    "\n",
    "val_data = data.on_the_fly(stft_params, transform=tfm, fg_path=configs['test_folder'], **configs['valid_generator_params'], duration=duration)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_data, num_workers=1, batch_size=configs['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96e7048d-e510-4d8f-aa67-91e3a0ba4123",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "overfit_selection=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5d1f42-6f9f-4c6b-aecd-244c18251657",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_type = configs['loss_type']\n",
    "loss_dict = {'L1': nussl.ml.train.loss.L1Loss,\n",
    "             'L2': nussl.ml.train.loss.MSELoss,\n",
    "             'MSE': nussl.ml.train.loss.MSELoss,}\n",
    "assert loss_type in loss_dict.keys(), f'Loss type must be one of {loss_dict.keys()}'\n",
    "loss_fn = loss_dict[loss_type]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1e350b9-02c7-4455-be2c-9648a073b433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #Forward pass\n",
    "    output = model(batch)\n",
    "    loss = loss_fn(output[output_key],batch[target_key])\n",
    "    \n",
    "    #Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vals = {'loss':loss.item()}\n",
    "    \n",
    "    return loss_vals\n",
    "\n",
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(batch)\n",
    "    loss = loss_fn(output[output_key],batch[target_key])  \n",
    "    loss_vals = {'loss':loss.item()}\n",
    "    return loss_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af54504b-28f3-44b1-9cbd-edde96fba28f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set up the model and optimizer\n",
    "if model_type=='Mask':\n",
    "    model = MaskInference.build(stft_params.window_length//2+1, **configs['model_params']).to(device)\n",
    "elif model_type=='UNet':\n",
    "    model = UNetSpect.build(**configs['model_params']).to(device)\n",
    "elif model_type=='Filterbank':\n",
    "    model = Filterbank.build(**configs['model_params']).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), **configs['optimizer_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c9b3da7-6cd3-4f34-81de-bf5bcd47fa58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,batch in enumerate(train_dataloader):\n",
    "    if i==overfit_selection:\n",
    "        batch=batch\n",
    "        break\n",
    "    \n",
    "for key in batch:\n",
    "    if torch.is_tensor(batch[key]):\n",
    "        batch[key] = batch[key].float().to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efc994af-6680-4ddd-95df-8d35a168e97d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs['optimizer_params']['lr'] = 1e-1\n",
    "optimizer = torch.optim.Adam(model.parameters(), **configs['optimizer_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd390164-607c-4656-9e4a-6cd028b98fab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create nussl ML engine\n",
    "trainer, validator = nussl.ml.train.create_train_and_validation_engines(train_step, val_step, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1dcec74-4ecd-4415-bc19-7946cb1bba0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 11.452027 at iteration 0\n",
      "Loss: 0.185101 at iteration 20\n",
      "Loss: 0.021633 at iteration 40\n",
      "Loss: 0.014579 at iteration 60\n",
      "Loss: 0.012950 at iteration 80\n",
      "Loss: 0.012403 at iteration 100\n",
      "Loss: 0.011581 at iteration 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_ITERATIONS = 200\n",
    "loss_history = [] # For bookkeeping\n",
    "\n",
    "for i in range(N_ITERATIONS):\n",
    "    loss_val = train_step(trainer,batch)\n",
    "    loss_history.append(loss_val['loss'])\n",
    "    if i%20==0:\n",
    "        print(f'Loss: {loss_val[\"loss\"]:.6f} at iteration {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d91d025-8c9f-48f8-ac06-82daba08d853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "configs['train_params']['epoch_length']=2\n",
    "configs['optimizer_params']['lr'] = 1e-10\n",
    "optimizer = torch.optim.Adam(model.parameters(), **configs['optimizer_params'])\n",
    "\n",
    "# Save model outputs\n",
    "checkpoint_folder = Path('overfit').absolute()\n",
    "\n",
    "# Adding handlers from nussl that print out details about model training\n",
    "# run the validation step, and save the models.\n",
    "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
    "nussl.ml.train.add_validate_and_checkpoint(checkpoint_folder, model, optimizer, train_data, trainer, val_dataloader, validator)\n",
    "nussl.ml.train.add_progress_bar_handler(trainer, validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b26e68-9eab-4b2d-b52f-ea001907fc32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.run(train_dataloader, **configs['train_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74829c-c8f3-45e6-b810-cc159f269d96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = batch[target_key].detach().numpy()\n",
    "output = model(batch)\n",
    "estimates = output[output_key].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce55786b-5189-4acb-b54c-315e200890a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(np.max(target))\n",
    "print(np.max(estimates))\n",
    "print(np.min(target))\n",
    "print(np.min(estimates))\n",
    "print(np.std(target))\n",
    "print(np.std(estimates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786dcaf8-3861-49c1-b684-f1ad372da492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load in the model\n",
    "if model_type in waveform_models:\n",
    "    separator = nussl.separation.deep.DeepAudioEstimation(\n",
    "        nussl.AudioSignal(), model_path='overfit/checkpoints/latest.model.pth',\n",
    "        device='cpu',\n",
    "    )\n",
    "else:\n",
    "    separator = nussl.separation.deep.DeepMaskEstimation(\n",
    "        nussl.AudioSignal(), model_path='overfit/checkpoints/latest.model.pth',\n",
    "        device='cpu',\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72275de-809c-46a8-9072-19e800e80eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test on the data\n",
    "test_folder = configs['test_folder']\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "])\n",
    "test_data = data.mixer(stft_params, transform=tfm, fg_path=configs['train_folder'], num_mixtures=1, coherent_prob=1.0, duration=5)\n",
    "\n",
    "test_data = data.on_the_fly(stft_params, transform=None, fg_path=configs['test_folder'], **configs['train_generator_params'], duration=duration)\n",
    "\n",
    "signal = test_data[overfit_selection]['mix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe41413e-9a9e-4c43-8a88-d72ce3b8341c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "separator.audio_signal = signal\n",
    "estimates = separator()\n",
    "estimates.append(signal - estimates[0])\n",
    "viz.show_sources(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa25e3a-a7eb-420a-a8da-ba77280070b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
