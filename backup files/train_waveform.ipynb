{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LpojGuWuL7b-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nussl\n",
    "import torch\n",
    "from nussl.datasets import transforms as nussl_tfm\n",
    "from models.Waveform import Waveform\n",
    "from utils import utils, data\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data.prepare_musdbhq(folder='data/musdb18hq/',musdb_root='/SFS/user/ry/stonekev/.nussl/',download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.logger()\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MAX_MIXTURES = int(1e8) # We'll set this to some impossibly high number for on the fly mixing.\n",
    "\n",
    "stft_params = nussl.STFTParams(window_length=512, hop_length=128)\n",
    "\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "    nussl_tfm.GetAudio(),\n",
    "    #nussl_tfm.MagnitudeSpectrumApproximation(),\n",
    "    nussl_tfm.IndexSources('source_audio', 1),\n",
    "    nussl_tfm.ToSeparationModel(),\n",
    "])\n",
    "\n",
    "train_folder = \"~/audio_isolation/data/musdb18hq/train\"\n",
    "val_folder = \"~/audio_isolation/data/musdb18hq/test\"\n",
    "\n",
    "train_data = data.on_the_fly(stft_params, transform=tfm, \n",
    "    fg_path=train_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_data, num_workers=1, batch_size=10)\n",
    "\n",
    "val_data = data.on_the_fly(stft_params, transform=tfm, \n",
    "    fg_path=val_folder, num_mixtures=10, coherent_prob=1.0)\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_data, num_workers=1, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 220500])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_data[0]['mix_audio']\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0009,  0.0016,  ..., -0.0013, -0.0005,  0.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimates': tensor([[[[-8.4832e-09],\n",
      "          [ 9.1094e-04],\n",
      "          [ 1.6035e-03],\n",
      "          ...,\n",
      "          [-1.2705e-03],\n",
      "          [-5.4304e-04],\n",
      "          [ 1.2505e-07]]]], dtype=torch.float64, grad_fn=<PermuteBackward0>)}\n"
     ]
    }
   ],
   "source": [
    "sample = train_data[0]['mix_audio'].unsqueeze(0)\n",
    "sample_model = Waveform(1025, 1, 50, 2, True, 0.3, 1, 2048, 512).double()\n",
    "sample_out = sample_model(sample)\n",
    "print(sample_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 220500, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_out['estimates'].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Waveform(\n",
       "  (stft): STFT()\n",
       "  (amplitude_to_db): AmplitudeToDB()\n",
       "  (input_normalization): BatchNorm(\n",
       "    (batch_norm): BatchNorm1d(1025, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (recurrent_stack): RecurrentStack(\n",
       "    (rnn): LSTM(1025, 50, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  )\n",
       "  (embedding): Embedding(\n",
       "    (linear): Linear(in_features=100, out_features=1025, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Waveform.build(1025, 1, 50, 2, True, 0.3, 1, 2048, 512)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nussl.ml.train.loss.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SeparationModel(\n",
       "  (layers): ModuleDict(\n",
       "    (model): Waveform(\n",
       "      (stft): STFT()\n",
       "      (amplitude_to_db): AmplitudeToDB()\n",
       "      (input_normalization): BatchNorm(\n",
       "        (batch_norm): BatchNorm1d(1025, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (recurrent_stack): RecurrentStack(\n",
       "        (rnn): LSTM(1025, 50, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "      )\n",
       "      (embedding): Embedding(\n",
       "        (linear): Linear(in_features=100, out_features=1025, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (estimates): Alias()\n",
       "  )\n",
       ")\n",
       "Number of parameters: 597175"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "executionInfo": {
     "elapsed": 9695,
     "status": "error",
     "timestamp": 1681264532589,
     "user": {
      "displayName": "Devin Cortese",
      "userId": "18217987079678842733"
     },
     "user_tz": 240
    },
    "id": "BMvsvbyJGxVB",
    "outputId": "367c59f2-1e56-445a-ad46-7afd3c966b12"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/27/2023 07:52:32 PM | engine.py:874 Engine run starting with max_epochs=2.\n",
      "04/27/2023 07:52:52 PM | engine.py:874 Engine run starting with max_epochs=1.\n",
      "04/27/2023 07:52:58 PM | engine.py:972 Epoch[1] Complete. Time taken: 00:00:04.572\n",
      "04/27/2023 07:52:58 PM | engine.py:988 Engine run complete. Time taken: 00:00:06.036\n",
      "04/27/2023 07:53:03 PM | trainer.py:311 \n",
      "\n",
      "EPOCH SUMMARY \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "- Epoch number: 0001 / 0002 \n",
      "- Training loss:   0.093904 \n",
      "- Validation loss: 0.115035 \n",
      "- Epoch took: 0:00:31.065096 \n",
      "- Time since start: 0:00:31.065127 \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "Saving to /Users/dev/audio_isolation/checkpoints/best.model.pth. \n",
      "Output @ /Users/dev/audio_isolation \n",
      "\n",
      "04/27/2023 07:53:03 PM | engine.py:972 Epoch[1] Complete. Time taken: 00:00:26.213\n",
      "04/27/2023 07:53:16 PM | engine.py:874 Engine run starting with max_epochs=1.\n",
      "04/27/2023 07:53:21 PM | engine.py:972 Epoch[1] Complete. Time taken: 00:00:04.596\n",
      "04/27/2023 07:53:21 PM | engine.py:988 Engine run complete. Time taken: 00:00:04.604\n",
      "04/27/2023 07:53:26 PM | trainer.py:311 \n",
      "\n",
      "EPOCH SUMMARY \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "- Epoch number: 0002 / 0002 \n",
      "- Training loss:   0.099595 \n",
      "- Validation loss: 0.115035 \n",
      "- Epoch took: 0:00:22.588238 \n",
      "- Time since start: 0:00:53.654090 \n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n",
      "Saving to /Users/dev/audio_isolation/checkpoints/best.model.pth. \n",
      "Output @ /Users/dev/audio_isolation \n",
      "\n",
      "04/27/2023 07:53:26 PM | engine.py:972 Epoch[2] Complete. Time taken: 00:00:22.589\n",
      "04/27/2023 07:53:26 PM | engine.py:988 Engine run complete. Time taken: 00:00:53.655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "State:\n",
       "\titeration: 20\n",
       "\tepoch: 2\n",
       "\tepoch_length: 10\n",
       "\tmax_epochs: 2\n",
       "\toutput: <class 'dict'>\n",
       "\tbatch: <class 'dict'>\n",
       "\tmetrics: <class 'dict'>\n",
       "\tdataloader: <class 'torch.utils.data.dataloader.DataLoader'>\n",
       "\tseed: <class 'NoneType'>\n",
       "\ttimes: <class 'dict'>\n",
       "\tepoch_history: <class 'dict'>\n",
       "\titer_history: <class 'dict'>\n",
       "\tpast_iter_history: <class 'dict'>\n",
       "\tsaved_model_path: /Users/dev/audio_isolation/checkpoints/best.model.pth\n",
       "\toutput_folder: <class 'pathlib.PosixPath'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nf = stft_params.window_length // 2 + 1\n",
    "# model = Waveform.build(nf, 1, 50, 1, True, 0.0, 1, 'sigmoid')\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# loss_fn = nussl.ml.train.loss.L1Loss()\n",
    "\n",
    "def train_step(engine, batch):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_audio'],\n",
    "    )\n",
    "    \n",
    "    loss.backward() # backwards + gradient step\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(),\n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    \n",
    "    return loss_vals\n",
    "\n",
    "def val_step(engine, batch):\n",
    "    with torch.no_grad():\n",
    "        output = model(batch) # forward pass\n",
    "    loss = loss_fn(\n",
    "        output['estimates'],\n",
    "        batch['source_audio']\n",
    "    )    \n",
    "    loss_vals = {\n",
    "        'L1Loss': loss.item(), \n",
    "        'loss': loss.item()\n",
    "    }\n",
    "    return loss_vals\n",
    "\n",
    "# Create the engines\n",
    "trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n",
    "    train_step, val_step, device=DEVICE\n",
    ")\n",
    "\n",
    "# We'll save the output relative to this notebook.\n",
    "output_folder = Path('.').absolute()\n",
    "\n",
    "# Adding handlers from nussl that print out details about model training\n",
    "# run the validation step, and save the models.\n",
    "nussl.ml.train.add_stdout_handler(trainer, validator)\n",
    "nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n",
    "    optimizer, train_data, trainer, val_dataloader, validator)\n",
    "\n",
    "trainer.run(\n",
    "    train_dataloader, \n",
    "    epoch_length=10, \n",
    "    max_epochs=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugIDanf4GxVF",
    "outputId": "2c025fca-07e0-4e80-ec75-c7ba500ea311"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dev/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/base/separation_base.py:73: UserWarning: input_audio_signal has no data!\n",
      "  warnings.warn('input_audio_signal has no data!')\n",
      "/Users/dev/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/core/audio_signal.py:455: UserWarning: Initializing STFT with data that is non-complex. This might lead to weird results!\n",
      "  warnings.warn('Initializing STFT with data that is non-complex. '\n"
     ]
    }
   ],
   "source": [
    "separator = nussl.separation.deep.DeepMaskEstimation(\n",
    "    nussl.AudioSignal(), model_path='checkpoints/best.model.pth',\n",
    "    device=DEVICE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m item \u001b[39m=\u001b[39m test_data[\u001b[39m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m separator\u001b[39m.\u001b[39maudio_signal \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39mmix\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 9\u001b[0m estimates \u001b[39m=\u001b[39m separator()\n\u001b[1;32m     10\u001b[0m \u001b[39m# Since our model only returns one source, let's tack on the\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# residual (which should be accompaniment)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m estimates\u001b[39m.\u001b[39mappend(item[\u001b[39m'\u001b[39m\u001b[39mmix\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m estimates[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/base/separation_base.py:194\u001b[0m, in \u001b[0;36mSeparationBase.__call__\u001b[0;34m(self, audio_signal, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m audio_signal \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_signal \u001b[39m=\u001b[39m audio_signal\n\u001b[0;32m--> 194\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    195\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_audio_signals()\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/deep/deep_mask_estimation.py:53\u001b[0m, in \u001b[0;36mDeepMaskEstimation.run\u001b[0;34m(self, masks)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresult_masks \u001b[39m=\u001b[39m []\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m masks \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     masks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward()\n\u001b[1;32m     55\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(masks\u001b[39m.\u001b[39mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]):\n\u001b[1;32m     56\u001b[0m     mask_data \u001b[39m=\u001b[39m masks[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, i]\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/deep/deep_mask_estimation.py:35\u001b[0m, in \u001b[0;36mDeepMaskEstimation.forward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m input_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_input_data_for_model(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m---> 35\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(input_data)\n\u001b[1;32m     36\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m output:\n\u001b[1;32m     37\u001b[0m         \u001b[39mraise\u001b[39;00m SeparationException(\n\u001b[1;32m     38\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThis model is not a deep mask estimation model! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mDid not find \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m\u001b[39m key in output dictionary.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/ml/networks/separation_model.py:181\u001b[0m, in \u001b[0;36mSeparationModel.forward\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m             input_data\u001b[39m.\u001b[39mappend(output[c] \u001b[39mif\u001b[39;00m c \u001b[39min\u001b[39;00m output \u001b[39melse\u001b[39;00m data[c])\n\u001b[0;32m--> 181\u001b[0m _output \u001b[39m=\u001b[39m layer(\u001b[39m*\u001b[39;49minput_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    182\u001b[0m added_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(_output, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/audio_isolation/models/WaveUNet.py:42\u001b[0m, in \u001b[0;36mWaveUNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     40\u001b[0m down_conv1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_conv1(data)\n\u001b[1;32m     41\u001b[0m down_conv1_max \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_pool(down_conv1)\n\u001b[0;32m---> 42\u001b[0m down_conv2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdown_conv2(down_conv1_max)\n\u001b[1;32m     43\u001b[0m down_conv2_max \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_pool(down_conv2)\n\u001b[1;32m     44\u001b[0m down_conv3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdown_conv3(down_conv2_max)\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/conv.py:313\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 313\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/conv.py:309\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv1d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    307\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    308\u001b[0m                     _single(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 309\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv1d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    310\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (2). Kernel size: (3). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "from utils import viz\n",
    "\n",
    "test_folder = \"~/audio_isolation/data/tutorial/test/\"\n",
    "test_data = data.mixer(stft_params, transform=None, \n",
    "    fg_path=test_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n",
    "item = test_data[0]\n",
    "\n",
    "separator.audio_signal = item['mix']\n",
    "estimates = separator()\n",
    "# Since our model only returns one source, let's tack on the\n",
    "# residual (which should be accompaniment)\n",
    "estimates.append(item['mix'] - estimates[0])\n",
    "\n",
    "viz.show_sources(estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-Xwu3xBGxVG"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tfm = nussl_tfm.Compose([\n",
    "    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n",
    "])\n",
    "#test_dataset = nussl.datasets.MUSDB18(subsets=['test'], transform=tfm)\n",
    "test_dataset = data.mixer(stft_params, transform=tfm, \n",
    "    fg_path=test_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n",
    "\n",
    "# Just do 5 items for speed. Change to 50 for actual experiment.\n",
    "for i in range(5):\n",
    "    item = test_dataset[i]\n",
    "    separator.audio_signal = item['mix']\n",
    "    estimates = separator()\n",
    "\n",
    "    source_keys = list(item['sources'].keys())\n",
    "    estimates = {\n",
    "        'vocals': estimates[0],\n",
    "        'bass+drums+other': item['mix'] - estimates[0]\n",
    "    }\n",
    "\n",
    "    sources = [item['sources'][k] for k in source_keys]\n",
    "    estimates = [estimates[k] for k in source_keys]\n",
    "\n",
    "    evaluator = nussl.evaluation.BSSEvalScale(\n",
    "        sources, estimates, source_labels=source_keys\n",
    "    )\n",
    "    scores = evaluator.evaluate()\n",
    "    output_folder = Path(output_folder).absolute()\n",
    "    output_folder.mkdir(exist_ok=True)\n",
    "    output_file = output_folder / sources[0].file_name.replace('wav', 'json') # Path(str(separator.audio_signal.file_name) + '.json')\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2X4GapzGxVH",
    "outputId": "98325d02-0c42-4fe9-d71f-e087dd3934d9"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "json_files = glob.glob(f\"*.json\")\n",
    "df = nussl.evaluation.aggregate_score_files(\n",
    "    json_files, aggregator=np.nanmedian)\n",
    "nussl.evaluation.associate_metrics(separator.model, df, test_dataset)\n",
    "report_card = nussl.evaluation.report_card(\n",
    "    df, report_each_source=True)\n",
    "print(report_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqD3uFSkGxVH",
    "outputId": "087131df-0e37-4458-dacd-10e4bd8af75a"
   },
   "outputs": [],
   "source": [
    "separator.model.save('checkpoints/best.model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPuwc-RqGxVH"
   },
   "outputs": [],
   "source": [
    "model_checkpoint = torch.load('checkpoints/best.model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6mM1Z0LGxVI",
    "outputId": "665fb444-a6fe-4307-8266-a1250a1b4d15"
   },
   "outputs": [],
   "source": [
    "model_checkpoint['metadata'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC6oQBFmGxVI",
    "outputId": "fdb01bd4-54ea-4ea1-a75a-d26bd9fe9691"
   },
   "outputs": [],
   "source": [
    "model_checkpoint['metadata']['evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EcQg01dbGxVI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
