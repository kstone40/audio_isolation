{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af8e6259-9ad5-498f-b075-6d070bc62e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, Video\n",
    "from torchaudio.pipelines import HDEMUCS_HIGH_MUSDB_PLUS\n",
    "from mir_eval import separation\n",
    "from torchaudio.transforms import Fade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8894fe56-e37e-417e-9388-8060d571fd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_specgram(waveform, sample_rate, title=\"Spectrogram\"):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].specgram(waveform[c], Fs=sample_rate)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(title)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e437f-d7a9-462f-8a65-d8f227532dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveform(waveform, sample_rate):\n",
    "    waveform = waveform.numpy()\n",
    "\n",
    "    num_channels, num_frames = waveform.shape\n",
    "    time_axis = torch.arange(0, num_frames) / sample_rate\n",
    "\n",
    "    figure, axes = plt.subplots(num_channels, 1)\n",
    "    if num_channels == 1:\n",
    "        axes = [axes]\n",
    "    for c in range(num_channels):\n",
    "        axes[c].plot(time_axis, waveform[c], linewidth=1)\n",
    "        axes[c].grid(True)\n",
    "        if num_channels > 1:\n",
    "            axes[c].set_ylabel(f\"Channel {c+1}\")\n",
    "    figure.suptitle(\"waveform\")\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ce4b8b-555a-4b36-a81d-a74798d687a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(torch.__version__) # 2.0.0\n",
    "print(torchaudio.__version__) # 2.0.0\n",
    "print(torchaudio._extension._FFMPEG_INITIALIZED) # True\n",
    "print(torch.cuda.is_available()) # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca35bf2-40cb-47ea-8ef1-a13a24a01787",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = 'data/demo/A Classic Education - NightOwl/mixture.wav'\n",
    "bass = 'data/demo/A Classic Education - NightOwl/bass.wav'\n",
    "drums = 'data/demo/A Classic Education - NightOwl/drums.wav'\n",
    "other = 'data/demo/A Classic Education - NightOwl/other.wav'\n",
    "vocals = 'data/demo/A Classic Education - NightOwl/vocals.wav'\n",
    "metadata = torchaudio.info(mixture)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42919e26-7902-4c39-935b-6ecbfdaf3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(mixture)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d682a7-35ce-4772-8ac2-e7e3a3467539",
   "metadata": {},
   "outputs": [],
   "source": [
    "bass_waveform, bass_sample_rate = torchaudio.load(bass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29f8b2c-8157-4d78-b29a-67c16d939811",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(waveform[:,0:10000], sample_rate) # waveform takes ~1 min to plot.  Trimming for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba705fa-67a0-4479-a28c-f52c82966c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_specgram(waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd51fbc-cbf0-45b9-8179-1c68b0b76bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveform(bass_waveform[:,0:10000], bass_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db941b85-445e-437e-8319-a627f4b58574",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_specgram(bass_waveform, bass_sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1afb352-1874-4f43-a301-32d188a7d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(mixture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb697b2-67a9-4bf1-803b-ff33efc70b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle = HDEMUCS_HIGH_MUSDB_PLUS\n",
    "\n",
    "model = bundle.get_model()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "sample_rate = bundle.sample_rate\n",
    "\n",
    "print(f\"Sample rate: {sample_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf85a4-f61d-4f8a-bfb0-d2aceec1650f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_sources(\n",
    "        model,\n",
    "        mix,\n",
    "        segment=10.,\n",
    "        overlap=0.1,\n",
    "        device=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Apply model to a given mixture. Use fade, and add segments together in order to add model segment by segment.\n",
    "\n",
    "    Args:\n",
    "        segment (int): segment length in seconds\n",
    "        device (torch.device, str, or None): if provided, device on which to\n",
    "            execute the computation, otherwise `mix.device` is assumed.\n",
    "            When `device` is different from `mix.device`, only local computations will\n",
    "            be on `device`, while the entire tracks will be stored on `mix.device`.\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = mix.device\n",
    "    else:\n",
    "        device = torch.device(device)\n",
    "\n",
    "    batch, channels, length = mix.shape\n",
    "\n",
    "    chunk_len = int(sample_rate * segment * (1 + overlap))\n",
    "    start = 0\n",
    "    end = chunk_len\n",
    "    overlap_frames = overlap * sample_rate\n",
    "    fade = Fade(fade_in_len=0, fade_out_len=int(overlap_frames), fade_shape='linear')\n",
    "\n",
    "    final = torch.zeros(batch, len(model.sources), channels, length, device=device)\n",
    "\n",
    "    while start < length - overlap_frames:\n",
    "        chunk = mix[:, :, start:end]\n",
    "        with torch.no_grad():\n",
    "            out = model.forward(chunk)\n",
    "        out = fade(out)\n",
    "        final[:, :, :, start:end] += out\n",
    "        if start == 0:\n",
    "            fade.fade_in_len = int(overlap_frames)\n",
    "            start += int(chunk_len - overlap_frames)\n",
    "        else:\n",
    "            start += chunk_len\n",
    "        end += chunk_len\n",
    "        if end >= length:\n",
    "            fade.fade_out_len = 0\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68fdd40-a376-488f-b4d0-288d5ff829a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(stft, title=\"Spectrogram\"):\n",
    "    magnitude = stft.abs()\n",
    "    spectrogram = 20 * torch.log10(magnitude + 1e-8).numpy()\n",
    "    figure, axis = plt.subplots(1, 1)\n",
    "    img = axis.imshow(spectrogram, cmap=\"viridis\", vmin=-60, vmax=0, origin=\"lower\", aspect=\"auto\")\n",
    "    figure.suptitle(title)\n",
    "    plt.colorbar(img, ax=axis)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7916cc5e-45c0-4be4-b589-abd8dd8bb4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load(mixture)  # replace SAMPLE_SONG with desired path for different song\n",
    "waveform = waveform.to(device)\n",
    "mixture = waveform\n",
    "\n",
    "# parameters\n",
    "segment: int = 10\n",
    "overlap = 0.1\n",
    "\n",
    "print(\"Separating track\")\n",
    "\n",
    "ref = waveform.mean(0)\n",
    "waveform = (waveform - ref.mean()) / ref.std()  # normalization\n",
    "\n",
    "sources = separate_sources(\n",
    "    model,\n",
    "    waveform[None],\n",
    "    device=device,\n",
    "    segment=segment,\n",
    "    overlap=overlap,\n",
    ")[0]\n",
    "sources = sources * ref.std() + ref.mean()\n",
    "\n",
    "sources_list = model.sources\n",
    "sources = list(sources)\n",
    "\n",
    "audios = dict(zip(sources_list, sources))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5566b-0ebe-4318-b687-58ace0c647fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 4096\n",
    "N_HOP = 4\n",
    "stft = torchaudio.transforms.Spectrogram(\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=N_HOP,\n",
    "    power=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5574a4-94c4-4ef2-bb40-d32da22dc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_results(original_source: torch.Tensor, predicted_source: torch.Tensor, source: str):\n",
    "    print(\"SDR score is:\",\n",
    "          separation.bss_eval_sources(\n",
    "              original_source.detach().numpy(),\n",
    "              predicted_source.detach().numpy())[0].mean())\n",
    "    plot_spectrogram(stft(predicted_source)[0], f'Spectrogram {source}')\n",
    "    return Audio(predicted_source, rate=sample_rate)\n",
    "\n",
    "\n",
    "segment_start = 150\n",
    "segment_end = 155\n",
    "\n",
    "frame_start = segment_start * sample_rate\n",
    "frame_end = segment_end * sample_rate\n",
    "\n",
    "drums_original = 'data/demo/A Classic Education - NightOwl/drums.wav'\n",
    "bass_original = 'data/hq/train/A Classic Education - NightOwl/bass.wav'\n",
    "vocals_original = 'data/demo/A Classic Education - NightOwl/vocals.wav'\n",
    "other_original = 'data/demo/A Classic Education - NightOwl/other.wav'\n",
    "\n",
    "drums_spec = audios[\"drums\"][:, frame_start: frame_end].cpu()\n",
    "drums, sample_rate = torchaudio.load(drums_original)\n",
    "\n",
    "bass_spec = audios[\"bass\"][:, frame_start: frame_end].cpu()\n",
    "bass, sample_rate = torchaudio.load(bass_original)\n",
    "\n",
    "vocals_spec = audios[\"vocals\"][:, frame_start: frame_end].cpu()\n",
    "vocals, sample_rate = torchaudio.load(vocals_original)\n",
    "\n",
    "other_spec = audios[\"other\"][:, frame_start: frame_end].cpu()\n",
    "other, sample_rate = torchaudio.load(other_original)\n",
    "\n",
    "mix_spec = mixture[:, frame_start: frame_end].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be697da-e54e-4f15-a97a-635a18d9ee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(stft(mix_spec)[0], \"Spectrogram Mixture\")\n",
    "Audio(mix_spec, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccdfd3-58db-476b-adc1-07d3fe476f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaecee6-d614-43e8-b610-1b9e45e39cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drums Clip\n",
    "output_results(vocals[:, frame_start: frame_end], vocals_spec, \"vocals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555d6c0-a542-4438-9c8f-f20b05bc8ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
