{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"LpojGuWuL7b-"},"outputs":[],"source":["import nussl\n","import torch\n","from nussl.datasets import transforms as nussl_tfm\n","from models.Waveform import Waveform\n","#from utils.models import MaskInference\n","from utils import utils, data\n","from pathlib import Path"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["#data.prepare_musdb('~/audio_isolation/data/tutorial/')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["utils.logger()\n","DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","MAX_MIXTURES = int(1e8) # We'll set this to some impossibly high number for on the fly mixing.\n","\n","stft_params = nussl.STFTParams(window_length=512, hop_length=128)\n","\n","tfm = nussl_tfm.Compose([\n","    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n","    nussl_tfm.GetAudio(),\n","    #nussl_tfm.MagnitudeSpectrumApproximation(),\n","    nussl_tfm.IndexSources('source_audio', 1),\n","    nussl_tfm.ToSeparationModel(),\n","])\n","\n","train_folder = \"~/audio_isolation/data/tutorial/train\"\n","val_folder = \"~/audio_isolation/data/tutorial/test\"\n","\n","train_data = data.on_the_fly(stft_params, n_channels=2, transform=tfm, \n","    fg_path=train_folder, num_mixtures=MAX_MIXTURES, coherent_prob=1.0)\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_data, num_workers=1, batch_size=10)\n","\n","val_data = data.on_the_fly(stft_params, n_channels=2, transform=tfm, \n","    fg_path=val_folder, num_mixtures=10, coherent_prob=1.0)\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_data, num_workers=1, batch_size=10)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["model = Waveform.build(1025, 2, 50, 2, True, 0.3, 1, 2048, 512)\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","loss_fn = nussl.ml.train.loss.L1Loss()"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/plain":["{'name': 'Waveform',\n"," 'modules': {'model': {'class': 'Waveform',\n","   'args': {'num_features': 1025,\n","    'num_audio_channels': 2,\n","    'hidden_size': 50,\n","    'num_layers': 2,\n","    'bidirectional': True,\n","    'dropout': 0.3,\n","    'embedding_size': 1,\n","    'num_filters': 2048,\n","    'hop_length': 512,\n","    'window_type': 'sqrt_hann',\n","    'activation': ['sigmoid', 'unit_norm']},\n","   'module_snapshot': \"class Waveform(nn.Module):\\n    def __init__(self, num_features, num_audio_channels, hidden_size,\\n                num_layers, bidirectional, dropout, embedding_size, \\n                num_filters, hop_length, window_type='sqrt_hann', # New STFT parameters\\n                activation=['sigmoid', 'unit_norm']):\\n        super().__init__()\\n        \\n        self.stft = STFT(\\n            num_filters, \\n            hop_length=hop_length, \\n            window_type=window_type\\n        )\\n        \\n        self.amplitude_to_db = AmplitudeToDB()\\n        self.input_normalization = BatchNorm(num_features)\\n        self.recurrent_stack = RecurrentStack(\\n            num_features * num_audio_channels, hidden_size, \\n            num_layers, bool(bidirectional), dropout\\n        )\\n        hidden_size = hidden_size * (int(bidirectional) + 1)\\n        self.embedding = Embedding(num_features, hidden_size, \\n                                embedding_size, activation, \\n                                num_audio_channels)\\n        \\n    def forward(self, data):\\n        # Take STFT inside model\\n        mix_stft = self.stft(data, direction='transform')\\n        nb, nt, nf, nac = mix_stft.shape\\n        # Stack the mag/phase along the second to last axis\\n        mix_stft = mix_stft.reshape(nb, nt, 2, -1, nac)\\n        mix_magnitude = mix_stft[:, :, 0, ...] # save for masking\\n        mix_phase = mix_stft[:, :, 1, ...] # save for reconstruction\\n        \\n        data = self.amplitude_to_db(mix_magnitude)\\n        data = self.input_normalization(data)\\n        data = self.recurrent_stack(data)\\n        mask = self.embedding(data)\\n        \\n        # Mask the mixture spectrogram\\n        estimates = mix_magnitude.unsqueeze(-1) * mask\\n        \\n        # Recombine estimates with mixture phase\\n        mix_phase = mix_phase.unsqueeze(-1).expand_as(estimates)\\n        estimates = torch.cat([estimates, mix_phase], dim=2)\\n        estimate_audio = self.stft(estimates, direction='inverse')\\n        \\n        output = {\\n            'estimates': estimate_audio\\n        }\\n        \\n        return output\\n\\n    @classmethod\\n    def build(cls, num_features, num_audio_channels, hidden_size,\\n                num_layers, bidirectional, dropout, embedding_size, \\n                num_filters, hop_length, window_type='sqrt_hann', # New STFT parameters\\n                activation=['sigmoid', 'unit_norm']):\\n        \\n        # Step 1. Register our model with nussl\\n        nussl.ml.register_module(cls)\\n        \\n        # Step 2a: Define the building blocks.\\n        modules = {\\n            'model': {\\n                'class': 'Waveform',\\n                'args': {\\n                    'num_features': num_features,\\n                    'num_audio_channels': num_audio_channels,\\n                    'hidden_size': hidden_size,\\n                    'num_layers': num_layers,\\n                    'bidirectional': bidirectional,\\n                    'dropout': dropout,\\n                    'embedding_size': embedding_size,\\n                    'num_filters': num_filters,\\n                    'hop_length': hop_length,\\n                    'window_type': window_type,\\n                    'activation': activation\\n                }\\n            }\\n        }\\n        \\n        \\n        # Step 2b: Define the connections between input and output.\\n        # Here, the mix_magnitude key is the only input to the model.\\n        connections = [\\n            ['model', ['mix_audio']]\\n        ]\\n        \\n        # Step 2c. The model outputs a dictionary, which SeparationModel will\\n        # change the keys to model:mask, model:estimates. The lines below \\n        # alias model:mask to just mask, and model:estimates to estimates.\\n        # This will be important later when we actually deploy our model.\\n        for key in ['estimates']:\\n            modules[key] = {'class': 'Alias'}\\n            connections.append([key, [f'model:{key}']])\\n        # modules['estimates'] = {'class': 'Alias'}\\n        # connections.append(['estimates', 'model: estimates'])\\n        \\n        # Step 2d. There are two outputs from our SeparationModel: estimates and mask.\\n        # Then put it all together.\\n        output = ['estimates']\\n        config = {\\n            'name': cls.__name__,\\n            'modules': modules,\\n            'connections': connections,\\n            'output': output\\n        }\\n        # Step 3. Instantiate the model as a SeparationModel.\\n        return nussl.ml.SeparationModel(config)\\n\"},\n","  'estimates': {'class': 'Alias',\n","   'module_snapshot': 'class Alias(nn.Module):\\n    \"\"\"\\n    Super simple module that just passes the data through without altering it, so\\n    that the output of a model can be renamed in a SeparationModel.\\n    \"\"\"\\n    def forward(self, data):\\n        return data\\n',\n","   'args': {}}},\n"," 'connections': [['model', ['mix_audio']], ['estimates', ['model:estimates']]],\n"," 'output': ['estimates']}"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["model.config"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":461},"executionInfo":{"elapsed":9695,"status":"error","timestamp":1681264532589,"user":{"displayName":"Devin Cortese","userId":"18217987079678842733"},"user_tz":240},"id":"BMvsvbyJGxVB","outputId":"367c59f2-1e56-445a-ad46-7afd3c966b12"},"outputs":[{"name":"stderr","output_type":"stream","text":["04/18/2023 05:59:45 PM | engine.py:874 Engine run starting with max_epochs=25.\n","04/18/2023 06:00:17 PM | engine.py:874 Engine run starting with max_epochs=1.\n","04/18/2023 06:00:22 PM | engine.py:972 Epoch[1] Complete. Time taken: 00:00:05.433\n","04/18/2023 06:00:22 PM | engine.py:988 Engine run complete. Time taken: 00:00:05.443\n","04/18/2023 06:00:28 PM | trainer.py:311 \n","\n","EPOCH SUMMARY \n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n","- Epoch number: 0001 / 0025 \n","- Training loss:   0.087930 \n","- Validation loss: 0.101172 \n","- Epoch took: 0:00:42.475676 \n","- Time since start: 0:00:42.475693 \n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n","Saving to /Users/dev/audio_isolation/checkpoints/best.model.pth. \n","Output @ /Users/dev/audio_isolation \n","\n","04/18/2023 06:00:28 PM | engine.py:972 Epoch[1] Complete. Time taken: 00:00:37.345\n","04/18/2023 06:00:51 PM | engine.py:874 Engine run starting with max_epochs=1.\n","04/18/2023 06:00:57 PM | engine.py:972 Epoch[1] Complete. Time taken: 00:00:05.529\n","04/18/2023 06:00:57 PM | engine.py:988 Engine run complete. Time taken: 00:00:05.538\n","04/18/2023 06:01:02 PM | trainer.py:311 \n","\n","EPOCH SUMMARY \n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n","- Epoch number: 0002 / 0025 \n","- Training loss:   0.095140 \n","- Validation loss: 0.101172 \n","- Epoch took: 0:00:34.153076 \n","- Time since start: 0:01:16.629519 \n","~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ \n","Saving to /Users/dev/audio_isolation/checkpoints/best.model.pth. \n","Output @ /Users/dev/audio_isolation \n","\n","04/18/2023 06:01:02 PM | engine.py:972 Epoch[2] Complete. Time taken: 00:00:34.153\n","04/18/2023 06:01:07 PM | engine.py:992 Engine run is terminating due to exception: \n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[7], line 51\u001b[0m\n\u001b[1;32m     47\u001b[0m nussl\u001b[39m.\u001b[39mml\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39madd_stdout_handler(trainer, validator)\n\u001b[1;32m     48\u001b[0m nussl\u001b[39m.\u001b[39mml\u001b[39m.\u001b[39mtrain\u001b[39m.\u001b[39madd_validate_and_checkpoint(output_folder, model, \n\u001b[1;32m     49\u001b[0m     optimizer, train_data, trainer, val_dataloader, validator)\n\u001b[0;32m---> 51\u001b[0m trainer\u001b[39m.\u001b[39;49mrun(\n\u001b[1;32m     52\u001b[0m     train_dataloader, \n\u001b[1;32m     53\u001b[0m     epoch_length\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, \n\u001b[1;32m     54\u001b[0m     max_epochs\u001b[39m=\u001b[39;49m\u001b[39m25\u001b[39;49m\n\u001b[1;32m     55\u001b[0m )\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/ignite/engine/engine.py:892\u001b[0m, in \u001b[0;36mEngine.run\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    889\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mdataloader \u001b[39m=\u001b[39m data\n\u001b[1;32m    891\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterrupt_resume_enabled:\n\u001b[0;32m--> 892\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_run()\n\u001b[1;32m    893\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_legacy()\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/ignite/engine/engine.py:935\u001b[0m, in \u001b[0;36mEngine._internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_generator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_as_gen()\n\u001b[1;32m    934\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 935\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_internal_run_generator)\n\u001b[1;32m    936\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m out:\n\u001b[1;32m    937\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_internal_run_generator \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/ignite/engine/engine.py:993\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    992\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39merror(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEngine run is terminating due to exception: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 993\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_exception(e)\n\u001b[1;32m    995\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    996\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/ignite/engine/engine.py:638\u001b[0m, in \u001b[0;36mEngine._handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mEXCEPTION_RAISED, e)\n\u001b[1;32m    637\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 638\u001b[0m     \u001b[39mraise\u001b[39;00m e\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/ignite/engine/engine.py:959\u001b[0m, in \u001b[0;36mEngine._internal_run_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataloader_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setup_engine()\n\u001b[0;32m--> 959\u001b[0m epoch_time_taken \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_once_on_dataset_as_gen()\n\u001b[1;32m    961\u001b[0m \u001b[39m# time is available for handlers but must be updated after fire\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mtimes[Events\u001b[39m.\u001b[39mEPOCH_COMPLETED\u001b[39m.\u001b[39mname] \u001b[39m=\u001b[39m epoch_time_taken\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/ignite/engine/engine.py:1068\u001b[0m, in \u001b[0;36mEngine._run_once_on_dataset_as_gen\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mITERATION_STARTED)\n\u001b[1;32m   1066\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_terminate_or_interrupt()\n\u001b[0;32m-> 1068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39moutput \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_function(\u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate\u001b[39m.\u001b[39;49mbatch)\n\u001b[1;32m   1069\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fire_event(Events\u001b[39m.\u001b[39mITERATION_COMPLETED)\n\u001b[1;32m   1070\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_terminate_or_interrupt()\n","Cell \u001b[0;32mIn[7], line 8\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_step\u001b[39m(engine, batch):\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 8\u001b[0m     output \u001b[39m=\u001b[39m model(batch) \u001b[39m# forward pass\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     loss \u001b[39m=\u001b[39m loss_fn(\n\u001b[1;32m     10\u001b[0m         output[\u001b[39m'\u001b[39m\u001b[39mestimates\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     11\u001b[0m         batch[\u001b[39m'\u001b[39m\u001b[39msource_audio\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     loss\u001b[39m.\u001b[39mbackward() \u001b[39m# backwards + gradient step\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/ml/networks/separation_model.py:181\u001b[0m, in \u001b[0;36mSeparationModel.forward\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m             input_data\u001b[39m.\u001b[39mappend(output[c] \u001b[39mif\u001b[39;00m c \u001b[39min\u001b[39;00m output \u001b[39melse\u001b[39;00m data[c])\n\u001b[0;32m--> 181\u001b[0m _output \u001b[39m=\u001b[39m layer(\u001b[39m*\u001b[39;49minput_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    182\u001b[0m added_keys \u001b[39m=\u001b[39m []\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(_output, \u001b[39mdict\u001b[39m):\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/audio_isolation/models/Waveform.py:33\u001b[0m, in \u001b[0;36mWaveform.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m     32\u001b[0m     \u001b[39m# Take STFT inside model\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     mix_stft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstft(data, direction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtransform\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m     nb, nt, nf, nac \u001b[39m=\u001b[39m mix_stft\u001b[39m.\u001b[39mshape\n\u001b[1;32m     35\u001b[0m     \u001b[39m# Stack the mag/phase along the second to last axis\u001b[39;00m\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/ml/networks/modules/filter_bank.py:238\u001b[0m, in \u001b[0;36mFilterBank.forward\u001b[0;34m(self, data, direction, **kwargs)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirection \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39minverse\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minverse\n\u001b[0;32m--> 238\u001b[0m \u001b[39mreturn\u001b[39;00m func(data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/ml/networks/modules/filter_bank.py:170\u001b[0m, in \u001b[0;36mFilterBank.transform\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    169\u001b[0m data \u001b[39m=\u001b[39m data \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow\n\u001b[0;32m--> 170\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_filter(data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m ndim \u001b[39m>\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[39m# then we moved sources to the batch dimension\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     \u001b[39m# we need to move it back before returning\u001b[39;00m\n\u001b[1;32m    175\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mreshape(\n\u001b[1;32m    176\u001b[0m         \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, num_sources, \u001b[39m*\u001b[39mdata\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m:])\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/ml/networks/modules/filter_bank.py:264\u001b[0m, in \u001b[0;36mSTFT.apply_filter\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirection \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    263\u001b[0m     scale \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msqrt(\u001b[39m1.0\u001b[39m \u001b[39m/\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow\u001b[39m.\u001b[39msum() \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m))\n\u001b[0;32m--> 264\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply_filter(data)\n\u001b[1;32m    265\u001b[0m     data \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m scale\n\u001b[1;32m    267\u001b[0m     eps \u001b[39m=\u001b[39m \u001b[39m1e-8\u001b[39m\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/ml/networks/modules/filter_bank.py:127\u001b[0m, in \u001b[0;36mFilterBank.apply_filter\u001b[0;34m(self, data, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[1;32m    126\u001b[0m data \u001b[39m=\u001b[39m data \u001b[39m@\u001b[39m filters\n\u001b[0;32m--> 127\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m    128\u001b[0m \u001b[39mreturn\u001b[39;00m data\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# nf = stft_params.window_length // 2 + 1\n","# model = Waveform.build(nf, 1, 50, 1, True, 0.0, 1, 'sigmoid')\n","# optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","# loss_fn = nussl.ml.train.loss.L1Loss()\n","\n","def train_step(engine, batch):\n","    optimizer.zero_grad()\n","    output = model(batch) # forward pass\n","    loss = loss_fn(\n","        output['estimates'],\n","        batch['source_audio']\n","    )\n","    \n","    loss.backward() # backwards + gradient step\n","    optimizer.step()\n","    \n","    loss_vals = {\n","        'L1Loss': loss.item(),\n","        'loss': loss.item()\n","    }\n","    \n","    return loss_vals\n","\n","def val_step(engine, batch):\n","    with torch.no_grad():\n","        output = model(batch) # forward pass\n","    loss = loss_fn(\n","        output['estimates'],\n","        batch['source_audio']\n","    )    \n","    loss_vals = {\n","        'L1Loss': loss.item(), \n","        'loss': loss.item()\n","    }\n","    return loss_vals\n","\n","# Create the engines\n","trainer, validator = nussl.ml.train.create_train_and_validation_engines(\n","    train_step, val_step, device=DEVICE\n",")\n","\n","# We'll save the output relative to this notebook.\n","output_folder = Path('.').absolute()\n","\n","# Adding handlers from nussl that print out details about model training\n","# run the validation step, and save the models.\n","nussl.ml.train.add_stdout_handler(trainer, validator)\n","nussl.ml.train.add_validate_and_checkpoint(output_folder, model, \n","    optimizer, train_data, trainer, val_dataloader, validator)\n","\n","trainer.run(\n","    train_dataloader, \n","    epoch_length=10, \n","    max_epochs=25\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ugIDanf4GxVF","outputId":"2c025fca-07e0-4e80-ec75-c7ba500ea311"},"outputs":[],"source":["separator = nussl.separation.deep.DeepMaskEstimation(\n","    nussl.AudioSignal(), model_path='checkpoints/best.model.pth',\n","    device=DEVICE,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/dev/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/base/separation_base.py:73: UserWarning: input_audio_signal has no data!\n","  warnings.warn('input_audio_signal has no data!')\n","/Users/dev/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/core/audio_signal.py:455: UserWarning: Initializing STFT with data that is non-complex. This might lead to weird results!\n","  warnings.warn('Initializing STFT with data that is non-complex. '\n"]}],"source":["separator = nussl.separation.deep.DeepAudioEstimation(\n","    nussl.AudioSignal(), model_path='checkpoints/best.model.pth',\n","    device=DEVICE,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-Xwu3xBGxVG"},"outputs":[{"ename":"SeparationException","evalue":"This model is not a deep audio estimation model! Did not find 'audio' key in output dictionary.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mSeparationException\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m item \u001b[39m=\u001b[39m test_dataset[i]\n\u001b[1;32m     11\u001b[0m separator\u001b[39m.\u001b[39maudio_signal \u001b[39m=\u001b[39m item[\u001b[39m'\u001b[39m\u001b[39mmix\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m estimates \u001b[39m=\u001b[39m separator()\n\u001b[1;32m     14\u001b[0m source_keys \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(item[\u001b[39m'\u001b[39m\u001b[39msources\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m     15\u001b[0m estimates \u001b[39m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mvocals\u001b[39m\u001b[39m'\u001b[39m: estimates[\u001b[39m0\u001b[39m],\n\u001b[1;32m     17\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbass+drums+other\u001b[39m\u001b[39m'\u001b[39m: item[\u001b[39m'\u001b[39m\u001b[39mmix\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m-\u001b[39m estimates[\u001b[39m0\u001b[39m]\n\u001b[1;32m     18\u001b[0m }\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/base/separation_base.py:194\u001b[0m, in \u001b[0;36mSeparationBase.__call__\u001b[0;34m(self, audio_signal, *args, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mif\u001b[39;00m audio_signal \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio_signal \u001b[39m=\u001b[39m audio_signal\n\u001b[0;32m--> 194\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    195\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_audio_signals()\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/deep/deep_audio_estimation.py:49\u001b[0m, in \u001b[0;36mDeepAudioEstimation.run\u001b[0;34m(self, audio)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m, audio\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m audio \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 49\u001b[0m         audio \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward()\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio \u001b[39m=\u001b[39m audio\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maudio\n","File \u001b[0;32m~/miniforge3/envs/audio-isolation/lib/python3.10/site-packages/nussl/separation/deep/deep_audio_estimation.py:35\u001b[0m, in \u001b[0;36mDeepAudioEstimation.forward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(input_data)\n\u001b[1;32m     34\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m output:\n\u001b[0;32m---> 35\u001b[0m     \u001b[39mraise\u001b[39;00m SeparationException(\n\u001b[1;32m     36\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis model is not a deep audio estimation model! \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDid not find \u001b[39m\u001b[39m'\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m'\u001b[39m\u001b[39m key in output dictionary.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m audio \u001b[39m=\u001b[39m output[\u001b[39m'\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     39\u001b[0m \u001b[39m# swap back batch and sample dims\u001b[39;00m\n","\u001b[0;31mSeparationException\u001b[0m: This model is not a deep audio estimation model! Did not find 'audio' key in output dictionary."]}],"source":["import json\n","\n","tfm = nussl_tfm.Compose([\n","    nussl_tfm.SumSources([['bass', 'drums', 'other']]),\n","])\n","test_dataset = nussl.datasets.MUSDB18(subsets=['test'], transform=tfm)\n","\n","# Just do 5 items for speed. Change to 50 for actual experiment.\n","for i in range(5):\n","    item = test_dataset[i]\n","    separator.audio_signal = item['mix']\n","    estimates = separator()\n","\n","    source_keys = list(item['sources'].keys())\n","    estimates = {\n","        'vocals': estimates[0],\n","        'bass+drums+other': item['mix'] - estimates[0]\n","    }\n","\n","    sources = [item['sources'][k] for k in source_keys]\n","    estimates = [estimates[k] for k in source_keys]\n","\n","    evaluator = nussl.evaluation.BSSEvalScale(\n","        sources, estimates, source_labels=source_keys\n","    )\n","    scores = evaluator.evaluate()\n","    output_folder = Path(output_folder).absolute()\n","    output_folder.mkdir(exist_ok=True)\n","    output_file = output_folder / sources[0].file_name.replace('wav', 'json')\n","    with open(output_file, 'w') as f:\n","        json.dump(scores, f, indent=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2X4GapzGxVH","outputId":"98325d02-0c42-4fe9-d71f-e087dd3934d9"},"outputs":[],"source":["import glob\n","import numpy as np\n","\n","json_files = glob.glob(f\"*.json\")\n","df = nussl.evaluation.aggregate_score_files(\n","    json_files, aggregator=np.nanmedian)\n","nussl.evaluation.associate_metrics(separator.model, df, test_dataset)\n","report_card = nussl.evaluation.report_card(\n","    df, report_each_source=True)\n","print(report_card)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mqD3uFSkGxVH","outputId":"087131df-0e37-4458-dacd-10e4bd8af75a"},"outputs":[],"source":["separator.model.save('checkpoints/best.model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aPuwc-RqGxVH"},"outputs":[],"source":["model_checkpoint = torch.load('checkpoints/best.model.pth')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6mM1Z0LGxVI","outputId":"665fb444-a6fe-4307-8266-a1250a1b4d15"},"outputs":[],"source":["model_checkpoint['metadata'].keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OC6oQBFmGxVI","outputId":"fdb01bd4-54ea-4ea1-a75a-d26bd9fe9691"},"outputs":[{"ename":"NameError","evalue":"name 'model_checkpoint' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_checkpoint[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mevaluation\u001b[39m\u001b[39m'\u001b[39m]\n","\u001b[0;31mNameError\u001b[0m: name 'model_checkpoint' is not defined"]}],"source":["model_checkpoint['metadata']['evaluation']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EcQg01dbGxVI"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"tutorial-environment","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
